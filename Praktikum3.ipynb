{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70d581c845f6bc6",
   "metadata": {},
   "source": [
    "# Praktikum 3\n",
    "\n",
    "Authors: Ahmed Khalil and Fiona Lublow\n",
    "\n",
    "Research question: How effective are different optimization strategies for improving accuracy and training speed of fully connected neural nets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6ff98235bf06c8",
   "metadata": {},
   "source": [
    "\n",
    "## Theory\n",
    "\n",
    "\n",
    "### Data and model choices\n",
    "\n",
    "We trained a fully connected neural network (FCNN) on the MNIST dataset, a benchmark in machine learning.\n",
    "\n",
    "To make a decision on the architecture of our neural net we consulted multiple sources:\n",
    "\n",
    "An, S., Lee, M., Park, S., Yang, H., & So, J. (2020). [An ensemble of simple convolutional neural network models for mnist digit recognition](https://arxiv.org/pdf/2008.10400). arXiv preprint arXiv:2008.10400.\n",
    "\n",
    "Montgomery, R. M. (2024). [Exploring Neural Networks: A Walk Through the MNIST Dataset Classification](https://www.researchgate.net/profile/Richard-Murdoch-Montgomery/publication/382678573_Exploring_Neural_Networks_A_Walk_Through_the_MNIST_Dataset_Classification/links/66cab445c2eaa5002314d834/Exploring-Neural-Networks-A-Walk-Through-the-MNIST-Dataset-Classification.pdf). ESS Open Archive eprints, 116, 11620168.\n",
    "\n",
    "Tabik, S., Peralta, D., Herrera-Poyatos, A., & Herrera, F. (2017). [A snapshot of image pre-processing for convolutional neural networks: case study of MNIST](https://link.springer.com/content/pdf/10.2991/ijcis.2017.10.1.38.pdf). International Journal of Computational Intelligence Systems, 10(1), 555-568.\n",
    "\n",
    " While convolutional neural networks (CNNs) are the modern standard due to their efficiency and performance, our focus was on basic optimization strategies, making the simpler FCNN architecture more suitable. Such networks, while limited to approximately three layers before degradation occurs, allow us to explore overfitting, a common issue when training larger models with many parameters.\n",
    "\n",
    "In fully connected neural networks, a maximum of around 3 layers are advisable, since more layers lead to vanishing gradients and slow learning.\n",
    "\n",
    "Modern approaches to MNIST reach higher accuracies, e.g. single CNN reached 99.75% accuracy in 2016.\n",
    "\n",
    "Hasanpour, S. H., Rouhani, M., Fayyaz, M., & Sabokrou, M. (2023). Let's keep it simple: Using simple architectures to outperform deeper and more complex architectures. arXiv. https://arxiv.org/abs/1608.06037\n",
    "\n",
    "Deeper fully connected networks with skip connections are being explored to reduce the work necessary for feature engineering in CNNs: Wang, R., Fu, B., Fu, G., & Wang, M. (2017). Deep & Cross Network for Ad Click Predictions. arXiv. https://arxiv.org/abs/1708.05123\n",
    "\n",
    "### Why optimize?\n",
    "\n",
    "Hahnloser, R. L. (1998). [On the piecewise analysis of networks of linear threshold neurons](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=a09ef3a49654fdbc7c446884369f8c9ca542b012). Neural Networks, 11(4), 691-697.\n",
    "\n",
    "Ying, X. (2019, February). [An overview of overfitting and its solutions](https://iopscience.iop.org/article/10.1088/1742-6596/1168/2/022022/pdf). In Journal of physics: Conference series (Vol. 1168, p. 022022). IOP Publishing.\n",
    "\n",
    "Hochreiter, S. (1998). [The vanishing gradient problem during learning recurrent neural nets and problem solutions](http://www.bioinf.jku.at/publications/older/2304.pdf). International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6(02), 107-116.\n",
    "\n",
    "Hochreiter, S., Bengio, Y., Frasconi, P., & Schmidhuber, J. (2001). [Gradient flow in recurrent nets: the difficulty of learning long-term dependencies](https://www.researchgate.net/profile/Y-Bengio/publication/2839938_Gradient_Flow_in_Recurrent_Nets_the_Difficulty_of_Learning_Long-Term_Dependencies/links/546cd26e0cf2193b94c577c2/Gradient-Flow-in-Recurrent-Nets-the-Difficulty-of-Learning-Long-Term-Dependencies.pdf).\n",
    "\n",
    "When training neural nets, we have to deal with the problem of overfitting:\n",
    "\n",
    "This occurs when a model becomes overly specific to training data, leading to poor generalization, often indicated by rising validation loss. This will eventually happen with any FCNN, given a complex enough NN. Optimization strategies not only combat this, but can also accelerate training.\n",
    "\n",
    "### Strategies:\n",
    "\n",
    "Marti, K. (2008). [Stochastic optimization methods](https://www.academia.edu/download/80852723/978-3-662-46214-0.pdf) (Vol. 2). Berlin: Springer.\n",
    "\n",
    "- Early stopping\n",
    "\n",
    "Bai, Y., Yang, E., Han, B., Yang, Y., Li, J., Mao, Y., ... & Liu, T. (2021). [Understanding and improving early stopping for learning with noisy labels. Advances in Neural Information Processing Systems](https://proceedings.neurips.cc/paper/2021/file/cc7e2b878868cbae992d1fb743995d8f-Paper.pdf), 34, 24392-24403.\n",
    "\n",
    "A simple way to deal with overfitting is to track the validation loss during training, and if it starts to rise, stop at that point. to improve the stopping point, we can keep backups of the NN during certain intervals, so we can go back to before it started to overfit. This can be expensive in memory.\n",
    "\n",
    "In our experiments, significant overfitting was not observed, likely due to our architecture and training parameters, so early stopping was not tested extensively.\n",
    "\n",
    "- Regularization\n",
    "\n",
    "Girosi, F., Jones, M., & Poggio, T. (1995). [Regularization theory and neural networks architectures](https://www.researchgate.net/profile/Michael-Jones-66/publication/2246342_Regularization_Theory_and_Neural_Networks_Architectures/links/02bfe50d33d1a45e52000000/Regularization-Theory-and-Neural-Networks-Architectures.pdf). Neural computation, 7(2), 219-269.\n",
    "\n",
    "Regularization helps control weight magnitudes, with L2 regularization being the most common.\n",
    "\n",
    "Regularization is applied to the weights of each layer, adjusting them to be in the same range.\n",
    "\n",
    "- Dropout\n",
    "\n",
    "Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). [Dropout: a simple way to prevent neural networks from overfitting](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf). The journal of machine learning research, 15(1), 1929-1958.\n",
    "\n",
    "Introduced by Srivastava et al. (2014), dropout reduces overfitting by randomly disabling a subset of nodes during training, effectively applying noise to the net. Disabled nodes do not contribute to forward passes or backpropagation. The trained weights are then all applied during evaluation and application of the model. Since they would overexcite the network, their values need to be adjusted by the same ratio that dropout was applied. This is handled by PyTorch's .eval() function. For our experiments, dropout was set to 50% to observe its impact.\n",
    "\n",
    "- ADAM\n",
    "\n",
    "Kingma, D.P., & Ba, J. (2014). [Adam: A Method for Stochastic Optimization](https://arxiv.org/pdf/1412.6980). CoRR, abs/1412.6980.\n",
    "\n",
    "One of the modern, established optimizers that combines different methods of tracking momentum and variance in momentum over multiple backpropagation steps. It is robust and generally requires little hyperparameter tuning, making it a popular choice today."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f63f52342176f16",
   "metadata": {},
   "source": [
    "## Description of Experiment\n",
    "\n",
    "We used  PyTorch to train and evaluate our neural network.\n",
    "\n",
    "The MNIST dataset was loaded via PyTorch and randomly split 80/20 into training and validation sets. Training data was split into batches of 64.\n",
    "\n",
    "Our intention is the examination of strategies that mainly combat overfitting, so we needed our architecture to give rise to overfitting. This is typically observed in larger neural networks with higher parameter counts.\n",
    "\n",
    "The input layer has a fixed size of 784, the output layer a size of 10.\n",
    "\n",
    "We applied ReLU activation for hidden layers and softmax for the output layer.\n",
    "\n",
    "As a starting point for number of parameters, Srivasta et al. (2014) tested Dropout with a neural network with 2 layers of 8192 nodes each.\n",
    "\n",
    "We used PyTorch implementation of stochastic gradient descent, better optimizers supplied by torch.optim such as ADAM are too \"good\" for us to see the effect of the strategies we wanted to test.\n",
    "\n",
    "Experiments were carried out with and without momentum, a setting of gradient descent function, which can help with getting stuck in low gradient zone and local minima.\n",
    "\n",
    "For our experiment, PyTorchâ€™s SGD optimizer includes L2 regularization via its weight decay parameter, set to 1e-4 our experiments.\n",
    "\n",
    "Dropout was applied via the dropout attribute of the model class. Dropout was set to 0.5, i.e. in each batch half of all hidden nodes are dropped. Reducing the weights in evaluation is automated by torch with the .eval() setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf70d9ec4e4ef0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T17:17:03.289015Z",
     "start_time": "2025-01-18T17:17:01.932163Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c9fdd38704603",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T13:54:52.354331Z",
     "start_time": "2025-01-18T13:54:52.295655Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the transforms: converts to tensor and normalizes\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the full training dataset\n",
    "full_train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Use a smaller subset for training (2000 entries)\n",
    "subset_size = 2000\n",
    "subset_indices = torch.randperm(len(full_train_dataset))[:subset_size]  # Randomly select 2000 indices\n",
    "train_dataset = torch.utils.data.Subset(full_train_dataset, subset_indices)\n",
    "\n",
    "# Use the remaining data for validation\n",
    "remaining_indices = list(set(range(len(full_train_dataset))) - set(subset_indices.tolist()))\n",
    "val_dataset = torch.utils.data.Subset(full_train_dataset, remaining_indices)\n",
    "\n",
    "# Load the test dataset\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32b518c32f6c27d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T13:54:54.849201Z",
     "start_time": "2025-01-18T13:54:54.843496Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the specific activation function for the hidden layers\n",
    "def get_activation_function(activation):\n",
    "    if activation == 'relu':\n",
    "        return F.relu\n",
    "    elif activation == 'sigmoid':\n",
    "        return torch.sigmoid\n",
    "    elif activation == 'tanh':\n",
    "        return torch.tanh\n",
    "    else:\n",
    "        raise ValueError(f\"Unbekannte Aktivierungsfunktion: {activation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8d753f29c8e8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T13:54:57.152324Z",
     "start_time": "2025-01-18T13:54:57.144130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Class to build up dynamic neural Networks\n",
    "# Allows specific hidden layers (define by the size of the list and the numbers of neurons init) and different activation functions\n",
    "class FullyConnectedNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, activation, dropout):\n",
    "        super(FullyConnectedNN, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=(0.5 if dropout == True else 0))\n",
    "\n",
    "        #empty List of hidden layers\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        current_size = input_size\n",
    "\n",
    "        # Creates the hidden layers and the specific amount of neurons at each iteration\n",
    "        for hidden_size in hidden_layers:\n",
    "            self.layers.append(nn.Linear(current_size, hidden_size))\n",
    "            # connect to the next layer\n",
    "            current_size = hidden_size\n",
    "\n",
    "        # output layer\n",
    "        self.layers.append(nn.Linear(current_size, output_size))\n",
    "\n",
    "        # Sets the activation function\n",
    "        self.activation = get_activation_function(activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = self.activation(layer(x))\n",
    "            if self.dropout.p > 0:\n",
    "                x = self.dropout(x)\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "\n",
    "    def get_accuracy(self, loader, device) -> float:\n",
    "        self.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                data = data.view(data.size(0), -1)\n",
    "                output = self(data)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        return correct / len(loader.dataset)\n",
    "\n",
    "    def get_loss(self, loader, device) -> float:\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                data = data.view(data.size(0), -1)\n",
    "                output = self(data)\n",
    "                loss = criterion(output, target)\n",
    "                total_loss += loss.item() * data.size(0)\n",
    "\n",
    "        avg_loss = total_loss / len(loader.dataset)\n",
    "        return avg_loss\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, test_loader, epochs, lr, L2_reg, optimizer_type):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = \\\n",
    "        (optim.SGD(model.parameters(), lr=lr,\n",
    "                   weight_decay=(1e-4 if L2_reg else 0)) if optimizer_type == \"SGD\"\n",
    "         else optim.Adam(model.parameters(), lr=lr))\n",
    "    criterion = nn.CrossEntropyLoss()  # includes softmax\n",
    "\n",
    "    training_history = []\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data = data.view(data.size(0), -1)\n",
    "\n",
    "            optimizer.zero_grad()  # Clear gradients\n",
    "            output = model(data)  # Forward pass\n",
    "            loss = criterion(output, target)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "        train_loss = model.get_loss(train_loader, device)\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss = model.get_loss(val_loader, device)\n",
    "\n",
    "        accuracy = model.get_accuracy(val_loader, device)\n",
    "\n",
    "        training_history.append({\n",
    "            \"Epoch\": epoch + 1,\n",
    "            \"Train Loss\": train_loss,\n",
    "            \"Validation Loss\": val_loss,\n",
    "            \"Accuracy\": accuracy,\n",
    "        })\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} | Train Loss: {train_loss:.4f} | Validation Loss: {val_loss:.4f} | Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    # Final accuracy on test set\n",
    "    accuracy = model.get_accuracy(test_loader, device)\n",
    "\n",
    "    output_csv = (\"./data/\"\n",
    "                  + str(hidden_layers)\n",
    "                  + optimizer_type\n",
    "                  + \"noMomentum\"\n",
    "                  + \"_\" \"dropout_\" + str(dropout) + \"_\"\n",
    "                  + \"L2_\" + str(L2_reg)\n",
    "                  + \".csv\")\n",
    "\n",
    "    with open(output_csv, mode='w', newline='') as csvfile:\n",
    "        csv_writer = csv.DictWriter(csvfile,\n",
    "                                    fieldnames=[\"Epoch\", \"Train Loss\", \"Validation Loss\", \"Accuracy\"],)\n",
    "        csv_writer.writeheader()\n",
    "        csv_writer.writerows(training_history)\n",
    "\n",
    "    return end_time - start_time, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed144d4106d6f5d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T14:31:42.805975Z",
     "start_time": "2025-01-18T14:31:42.804186Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 28 * 28\n",
    "output_size = 10\n",
    "hidden_layers = [2024]\n",
    "activation = 'relu'\n",
    "optimizer_type = \"SGD\"\n",
    "epochs = 500\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9e9279c044a8ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T15:57:08.451354Z",
     "start_time": "2025-01-18T15:15:11.888393Z"
    }
   },
   "outputs": [],
   "source": [
    "dropout = True\n",
    "L2_reg = True\n",
    "\n",
    "\n",
    "model1 = FullyConnectedNN(input_size, output_size, hidden_layers, activation, dropout)\n",
    "print(f\"Model loaded, starting training...\")\n",
    "time1, accuracy1 = train_and_evaluate(model1, train_loader, val_loader, test_loader, epochs, learning_rate, L2_reg,\n",
    "                                      optimizer_type)\n",
    "print(f\"Model 1: Time={time1:.2f}s, test accuracy={accuracy1:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e0cbfea5415c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T16:36:32.571624Z",
     "start_time": "2025-01-18T15:57:08.492449Z"
    }
   },
   "outputs": [],
   "source": [
    "dropout = True\n",
    "L2_reg = False\n",
    "\n",
    "\n",
    "model2 = FullyConnectedNN(input_size, output_size, hidden_layers, activation, dropout)\n",
    "print(f\"Model loaded, starting training...\")\n",
    "time2, accuracy2 = train_and_evaluate(model2, train_loader, val_loader, test_loader, epochs, learning_rate, L2_reg,\n",
    "                                      optimizer_type)\n",
    "print(f\"Model 1: Time={time2:.2f}s, test accuracy={accuracy2:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c9631450ab9633",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T17:13:49.649316Z",
     "start_time": "2025-01-18T16:36:32.591181Z"
    }
   },
   "outputs": [],
   "source": [
    "dropout = False\n",
    "L2_reg = True\n",
    "\n",
    "\n",
    "model3 = FullyConnectedNN(input_size, output_size, hidden_layers, activation, dropout)\n",
    "print(f\"Model loaded, starting training...\")\n",
    "time3, accuracy3 = train_and_evaluate(model3, train_loader, val_loader, test_loader, epochs, learning_rate, L2_reg,\n",
    "                                      optimizer_type)\n",
    "print(f\"Model 1: Time={time3:.2f}s, test accuracy={accuracy3:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93104f5c5d943972",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T15:15:11.869695Z",
     "start_time": "2025-01-18T14:31:48.339850Z"
    }
   },
   "outputs": [],
   "source": [
    "dropout = False\n",
    "L2_reg = False\n",
    "\n",
    "\n",
    "model4 = FullyConnectedNN(input_size, output_size, hidden_layers, activation, dropout)\n",
    "print(f\"Model loaded, starting training...\")\n",
    "time4, accuracy4 = train_and_evaluate(model4, train_loader, val_loader, test_loader, epochs, learning_rate, L2_reg,\n",
    "                                      optimizer_type)\n",
    "print(f\"Model 1: Time={time4:.2f}s, test accuracy={accuracy4:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd598b3417cea7e5",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "Using the full dataset of 60.000 images we were not able to observe clear overfitting by looking at the validation loss, even with larger networks (two hidden layers of 8192 Nodes).\n",
    "\n",
    "Using a smaller subset of 2.000 images for training did lead to rising validation loss.\n",
    "\n",
    "With a network of one hidden layer of 20424 nodes, after 500 epochs we reached around 91.44% accuracy with both dropout and regularization, and 90.59% accuracy without those.\n",
    "\n",
    "Just L2 Regularization reached 90.65% accuracy, just Dropout reached 91.67% accuracy.\n",
    "\n",
    "Overfitting is also signified by a large difference in training vs validation loss, this can be observed in our collected data.\n",
    "\n",
    "With the same hyperparameters, there was a difference in training loss (\\~0.0332) and validation loss (\\~0.385) with no dropout and L2, vs a difference of training loss (\\~0.028) and validation loss (\\~0.331) with both dropout and L2.\n",
    "\n",
    "\n",
    "> none:\n",
    "\n",
    "> Epoch 500/500 | Train Loss: 0.0332 | Validation Loss: 0.3854 | Accuracy: 89.81%\n",
    "Model 1: Time=2603.10s, test accuracy=90.59%\n",
    "\n",
    "> just dropout:\n",
    "\n",
    "> Epoch 500/500 | Train Loss: 0.0268 | Validation Loss: 0.3265 | Accuracy: 90.92%\n",
    "Model 1: Time=2363.71s, test accuracy=91.67%\n",
    "\n",
    "> just L2:\n",
    "\n",
    "> Epoch 500/500 | Train Loss: 0.0331 | Validation Loss: 0.3809 | Accuracy: 89.90%\n",
    "Model 1: Time=2236.66s, test accuracy=90.65%\n",
    "\n",
    "> both:\n",
    "\n",
    "> Epoch 500/500 | Train Loss: 0.0280 | Validation Loss: 0.3305 | Accuracy: 90.84%\n",
    "Model 1: Time=2516.10s, test accuracy=91.44%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf1c3c27d85c16c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T17:18:20.243871Z",
     "start_time": "2025-01-18T17:18:20.037687Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/[2024]SGDnoMomentum_dropout_True_L2_True.csv\")\n",
    "\n",
    "fig = px.line(df, x=\"Epoch\", y=[\"Train Loss\", \"Validation Loss\"],\n",
    "              labels={\"Epoch\": \"Epoch\", \"value\": \"Value\"},\n",
    "              title=\"Train and Validation Loss with L2 Regularization and Dropout\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7820f2db22ce16a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T17:18:22.830014Z",
     "start_time": "2025-01-18T17:18:22.806307Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/[2024]SGDnoMomentum_dropout_False_L2_True.csv\")\n",
    "\n",
    "fig = px.line(df, x=\"Epoch\", y=[\"Train Loss\", \"Validation Loss\"],\n",
    "              labels={\"Epoch\": \"Epoch\", \"value\": \"Value\"},\n",
    "              title=\"Train and Validation Loss only L2 Regularization\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368bea7e51486a7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T17:18:29.797545Z",
     "start_time": "2025-01-18T17:18:29.772777Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/[2024]SGDnoMomentum_dropout_True_L2_False.csv\")\n",
    "\n",
    "fig = px.line(df, x=\"Epoch\", y=[\"Train Loss\", \"Validation Loss\"],\n",
    "              labels={\"Epoch\": \"Epoch\", \"value\": \"Value\"},\n",
    "              title=\"Train and Validation Loss only Dropout\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77474bbad0836e11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T17:18:31.373238Z",
     "start_time": "2025-01-18T17:18:31.352208Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/[2024]SGDnoMomentum_dropout_False_L2_False.csv\")\n",
    "\n",
    "fig = px.line(df, x=\"Epoch\", y=[\"Train Loss\", \"Validation Loss\"],\n",
    "              labels={\"Epoch\": \"Epoch\", \"value\": \"Value\"},\n",
    "              title=\"Train and Validation Loss without optimization\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea0f1da37e7c17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T17:32:50.477894Z",
     "start_time": "2025-01-18T17:32:50.440025Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_csvs = \"./data/*.csv\"\n",
    "\n",
    "# Read all CSV files and add an identifier column\n",
    "all_files = glob.glob(path_to_csvs)\n",
    "df_list = []\n",
    "\n",
    "for file in all_files:\n",
    "    if not file.__contains__(\"2024\"):\n",
    "        continue\n",
    "    temp_df = pd.read_csv(file)\n",
    "\n",
    "    # Add a column to identify which file/experiment this is\n",
    "    temp_df['Experiment'] = file.split('/')[-1].replace('.csv', '')  # Use filename as experiment name\n",
    "\n",
    "    df_list.append(temp_df)\n",
    "\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Melt the dataframe for easier plotting\n",
    "# We want 'Epoch' on the x-axis and values from 'Train Loss', 'Validation Loss', and 'Accuracy' on the y-axis\n",
    "melted_df = combined_df.melt(\n",
    "    id_vars=['Epoch', 'Experiment'],\n",
    "    value_vars=['Train Loss', 'Validation Loss'],\n",
    "    var_name='Metric',\n",
    "    value_name='Value'\n",
    ")\n",
    "\n",
    "fig = px.line(\n",
    "    melted_df,\n",
    "    x='Epoch',\n",
    "    y='Value',\n",
    "    color='Experiment',  # Different lines for each experiment\n",
    "    line_dash='Metric',  # Different line styles for Train Loss and Validation Loss\n",
    "    title='Training Progress Across Experiments',\n",
    "    labels={'Value': 'Metric Value', 'Epoch': 'Epoch'},\n",
    "    template='plotly',\n",
    "    log_y= True\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b629bdab1e084e66",
   "metadata": {},
   "source": [
    "The figure above shows that L2 had only a small effect, but dropout was effective.\n",
    "\n",
    "We observe that without dropout the validation loss starts to rise from \\~0.355 after about 170 epochs to \\~0.385 at 500 epochs. With dropout it steadily descends to \\~0.33."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fdf8e155405ecf",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "Implementations of NN in modern libraries are very optimized, and it was hard to find information on making a \"bad\" NN, thus observing heavy overfitting was difficult. The \"worst\" optimizer in PyTorch, the stochastic gradient descent optimizer, is quite advanced compared to what was available to researches historically when less advanced architectures (FCNN) were in the focus.\n",
    "\n",
    "Maybe doing more research on a problem that is known to lead to overfitting faster, would have enabled us to start in a better direction.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
